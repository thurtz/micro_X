# modules/lc_agent.py

import logging
import re
from typing import TypedDict, Annotated, Sequence, Literal
import operator

from langchain_core.messages import BaseMessage, HumanMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_ollama import ChatOllama
from langgraph.graph import StateGraph, END

# --- Logging Setup ---
logger = logging.getLogger(__name__)

# --- Helper Functions (migrated from ai_handler.py) ---

def _is_ai_refusal(text: str) -> bool:
    """Checks if a given text is likely an AI refusal to generate a command."""
    refusal_prefixes = ("sorry", "i cannot", "unable to", "cannot translate", "i am unable to")
    return text.lower().strip().startswith(refusal_prefixes)

def _clean_extracted_command(extracted_candidate: str) -> str:
    """Applies common cleaning steps to a potential command string."""
    # This cleaning logic can be refined over time
    processed_candidate = extracted_candidate.strip()
    if processed_candidate.startswith("`") and processed_candidate.endswith("`"):
        processed_candidate = processed_candidate[1:-1].strip()
    if processed_candidate.startswith("'") and processed_candidate.endswith("'"):
        processed_candidate = processed_candidate[1:-1].strip()
    if _is_ai_refusal(processed_candidate):
        return ""
    return processed_candidate

# --- LangGraph State Definition ---

class AgentState(TypedDict):
    """
    Represents the state of our agent. It's passed between nodes in the graph.
    """
    human_query: str
    config_param: dict
    
    # The command generated by the primary translator
    primary_command: str | None
    
    # The command generated by the secondary translator
    secondary_command: str | None
    
    # The final, validated command to be executed
    validated_command: str | None
    
    # The raw response from the last LLM call
    raw_response: str | None
    
    # A log of messages for debugging or interaction
    messages: Annotated[Sequence[BaseMessage], operator.add]
    
    # The number of cycles/retries the agent has attempted
    cycle_count: int
    
    # The final decision on which command to use
    decision: Literal["primary", "secondary", "fail"] | None


# --- LangGraph Node Definitions ---

async def primary_translator_node(state: AgentState) -> AgentState:
    """
    Calls the primary translator LLM to convert the human query into a command.
    """
    logger.info("--- Calling Primary Translator Node ---")
    config = state["config_param"]
    
    # 1. Extract configuration
    primary_config = config.get('ai_models', {}).get('primary_translator', {})
    model_name = primary_config.get('model') if isinstance(primary_config, dict) else primary_config
    
    system_prompt = config.get('prompts', {}).get('primary_translator', {}).get('system', "")
    user_template = config.get('prompts', {}).get('primary_translator', {}).get('user_template', "{human_input}")

    if not model_name:
        logger.error("Primary Translator model not configured.")
        return {"primary_command": None, "raw_response": "Primary model not configured."}

    # 2. Set up LangChain chain
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("user", user_template)
    ])
    model = ChatOllama(model=model_name)
    chain = prompt | model | StrOutputParser()

    # 3. Invoke the chain
    raw_output = await chain.ainvoke({"human_input": state["human_query"]})
    
    # 4. Clean the output
    cleaned_command = _clean_extracted_command(raw_output)
    
    logger.info(f"Primary translator generated: '{cleaned_command}'")
    
    return {
        "primary_command": cleaned_command,
        "raw_response": raw_output,
        "messages": [HumanMessage(content=f"Primary translator output: {raw_output}")]
    }

async def validator_node(state: AgentState) -> AgentState:
    """
    Calls the validator LLM to check if the generated command is a valid Linux command.
    """
    logger.info("--- Calling Validator Node ---")
    config = state["config_param"]
    command_to_validate = state["primary_command"]

    if not command_to_validate:
        logger.warning("Validator node called with no command to validate.")
        return {"decision": "fail"}

    # 1. Extract configuration
    validator_config = config.get('ai_models', {}).get('validator', {})
    model_name = validator_config.get('model') if isinstance(validator_config, dict) else validator_config
    
    system_prompt = config.get('prompts', {}).get('validator', {}).get('system', "")
    user_template = config.get('prompts', {}).get('validator', {}).get('user_template', "{command_text}")

    if not model_name:
        logger.error("Validator model not configured.")
        # If no validator, we can choose to either fail or proceed with caution.
        # For now, let's consider the command valid and move on.
        return {"decision": "primary", "validated_command": command_to_validate}

    # 2. Set up LangChain chain
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("user", user_template)
    ])
    model = ChatOllama(model=model_name)
    chain = prompt | model | StrOutputParser()

    # 3. Invoke the chain
    response = await chain.ainvoke({"command_text": command_to_validate})
    logger.info(f"Validator response for '{command_to_validate}': '{response}'")
    
    # 4. Process response
    if 'yes' in response.lower():
        logger.info("Validator approved the command.")
        return {"decision": "primary", "validated_command": command_to_validate, "messages": [HumanMessage(content=f"Validator approved: {command_to_validate}")]}
    else:
        logger.warning("Validator rejected the command.")
        return {"decision": None, "messages": [HumanMessage(content=f"Validator rejected: {command_to_validate}")]}


def route_after_primary(state: AgentState) -> Literal["validator", "secondary_translator"]:
    """
    Determines the next step after the primary translator has run.
    If a command was generated, validate it. Otherwise, try the secondary translator.
    """
    if state.get("primary_command"):
        logger.info("Routing to: Validator")
        return "validator"
    else:
        logger.info("Routing to: Secondary Translator")
        return "secondary_translator"


# --- Graph Definition (In Progress) ---

# TODO: Add other nodes (validator, secondary_translator, etc.)
# TODO: Define conditional edges

async def secondary_translator_node(state: AgentState) -> AgentState:
    """
    Calls the secondary (direct) translator LLM as a fallback.
    """
    logger.info("--- Calling Secondary Translator Node ---")
    config = state["config_param"]
    
    # 1. Extract configuration
    secondary_config = config.get('ai_models', {}).get('direct_translator', {})
    model_name = secondary_config.get('model') if isinstance(secondary_config, dict) else secondary_config
    
    system_prompt = config.get('prompts', {}).get('direct_translator', {}).get('system', "")
    user_template = config.get('prompts', {}).get('direct_translator', {}).get('user_template', "{human_input}")

    if not model_name:
        logger.error("Secondary Translator model not configured.")
        return {"secondary_command": None, "raw_response": "Secondary model not configured."}

    # 2. Set up LangChain chain
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("user", user_template)
    ])
    model = ChatOllama(model=model_name)
    chain = prompt | model | StrOutputParser()

    # 3. Invoke the chain
    raw_output = await chain.ainvoke({"human_input": state["human_query"]})
    
    # 4. Clean the output
    cleaned_command = _clean_extracted_command(raw_output)
    
    logger.info(f"Secondary translator generated: '{cleaned_command}'")
    
    # The secondary command is sent to the validator next
    return {
        "primary_command": cleaned_command, # We overwrite primary_command to reuse the validator
        "raw_response": raw_output,
        "messages": [HumanMessage(content=f"Secondary translator output: {raw_output}")]
    }


def route_after_validator(state: AgentState) -> Literal["secondary_translator", "__end__"]:
    """
    Determines the next step after the validator has run.
    If the command was approved, end. Otherwise, try the secondary translator.
    """
    if state.get("decision") == "primary":
        logger.info("Routing to: END (Success)")
        return END
    else:
        logger.info("Routing to: Secondary Translator")
        return "secondary_translator"


# --- Graph Definition ---

async def run_agent(human_query: str, config_param: dict) -> tuple[str | None, str | None]:
    """Runs the LangGraph agent to get a validated shell command."""
    
    workflow = StateGraph(AgentState)

    # Add nodes
    workflow.add_node("primary_translator", primary_translator_node)
    workflow.add_node("validator", validator_node)
    workflow.add_node("secondary_translator", secondary_translator_node)

    # Define edges
    workflow.set_entry_point("primary_translator")
    workflow.add_conditional_edges(
        "primary_translator",
        route_after_primary,
        {
            "validator": "validator",
            "secondary_translator": "secondary_translator"
        }
    )
    workflow.add_conditional_edges(
        "validator",
        route_after_validator,
        {
            "secondary_translator": "secondary_translator",
            "__end__": END
        }
    )
    # After the secondary translator, we re-route to the validator.
    # This creates the loop.
    workflow.add_edge("secondary_translator", "validator")

    app = workflow.compile()

    # Introduce retry logic
    max_cycles = config_param.get('behavior', {}).get('translation_validation_cycles', 2)
    final_state = None

    for i in range(max_cycles):
        initial_state: AgentState = {
            "human_query": human_query,
            "config_param": config_param,
            "primary_command": None,
            "secondary_command": None,
            "validated_command": None,
            "raw_response": None,
            "messages": [HumanMessage(content=f"--- Agent Cycle {i+1}/{max_cycles} ---")],
            "cycle_count": i,
            "decision": None
        }
        
        final_state = await app.ainvoke(initial_state)
        if final_state.get("decision"):
            break # Exit loop on success or handled failure
    
    logger.info(f"Agent finished with decision: {final_state.get('decision')}")
    return (final_state.get("validated_command"), final_state.get("raw_response"))
